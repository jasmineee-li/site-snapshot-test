WARNING:root:Module agentlab has uncommitted changes. Ignoring changes as requested and proceeding to experiments.
[92m11:49:59 - LiteLLM:DEBUG[0m: utils.py:4760 - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-05-13', 'combined_model_name': 'gpt-4o-2024-05-13', 'stripped_model_name': 'gpt-4o-2024-05-13', 'combined_stripped_model_name': 'gpt-4o-2024-05-13', 'custom_llm_provider': 'openai'}
[92m11:49:59 - LiteLLM:DEBUG[0m: utils.py:5087 - model_info: {'key': 'gpt-4o-2024-05-13', 'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': 8.75e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 2.5e-06, 'output_cost_per_token_batches': 7.5e-06, 'output_cost_per_token': 1.5e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': 2.625e-05, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': None, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
Searching experiments directories.:   0%|          | 0/1 [00:00<?, ?it/s]Searching experiments directories.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 3258.98it/s]
Loading results:   0%|          | 0/1 [00:00<?, ?it/s]Loading results: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 664.39it/s]
[92m11:54:50 - LiteLLM:DEBUG[0m: utils.py:4760 - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-05-13', 'combined_model_name': 'gpt-4o-2024-05-13', 'stripped_model_name': 'gpt-4o-2024-05-13', 'combined_stripped_model_name': 'gpt-4o-2024-05-13', 'custom_llm_provider': 'openai'}
[92m11:54:50 - LiteLLM:DEBUG[0m: utils.py:5087 - model_info: {'key': 'gpt-4o-2024-05-13', 'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': 8.75e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 2.5e-06, 'output_cost_per_token_batches': 7.5e-06, 'output_cost_per_token': 1.5e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': 2.625e-05, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': None, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
Searching experiments directories.:   0%|          | 0/2 [00:00<?, ?it/s]Searching experiments directories.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12035.31it/s]
Loading results:   0%|          | 0/1 [00:00<?, ?it/s]Loading results: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 956.95it/s]
[92m12:02:23 - LiteLLM:DEBUG[0m: utils.py:4760 - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-05-13', 'combined_model_name': 'gpt-4o-2024-05-13', 'stripped_model_name': 'gpt-4o-2024-05-13', 'combined_stripped_model_name': 'gpt-4o-2024-05-13', 'custom_llm_provider': 'openai'}
[92m12:02:23 - LiteLLM:DEBUG[0m: utils.py:5087 - model_info: {'key': 'gpt-4o-2024-05-13', 'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': 8.75e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 2.5e-06, 'output_cost_per_token_batches': 7.5e-06, 'output_cost_per_token': 1.5e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': 2.625e-05, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': None, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
Searching experiments directories.:   0%|          | 0/3 [00:00<?, ?it/s]Searching experiments directories.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 24197.91it/s]
Loading results:   0%|          | 0/1 [00:00<?, ?it/s]Loading results: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 439.33it/s]
2025-10-31 12:08:05,583 - 36387 - agentlab.experiments.study - WARNING - Study genericagent-gpt-4o-2024-05-13-on-redteam did not finish after 3 trials. There are 1 incomplete experiments.
